{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-UlVFX2IPMJ"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pjyi2147/CUDA_HTN_Workshop/blob/main/notebook.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT4VGU1cKs17"
      },
      "source": [
        "# 0. Setup\n",
        "\n",
        "## Select GPU for CUDA\n",
        "\n",
        "Select `Runtime -> Change Runtime Type -> Select Python and T4 GPU`\n",
        "\n",
        "Press Connect T4 on top right of the notebook.\n",
        "\n",
        "Run the following snippets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48mFPwioIJd_",
        "outputId": "c6c2d68a-e5cd-4b39-cb9e-6e240815215f"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UhQaRtyM4f6",
        "outputId": "36759519-9ea9-4e9e-cd3c-2db5d413b5ef"
      },
      "outputs": [],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJerVp82M-At",
        "outputId": "e2698ff2-8334-4fbc-f7f8-581b6261fb40"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yr-sEEqPsFi"
      },
      "source": [
        "You should get something similar to this:\n",
        "\n",
        "![Jupyter result](https://github.com/user-attachments/assets/eff2ae68-0b50-4e8e-8e73-26ccc5563754)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3hYM0E8IObd"
      },
      "source": [
        "# 2. Hello World!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9gwAQDzUdBe",
        "outputId": "c0fbd377-034d-4324-8aec-fc7f3203fc7c"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// Host (CPU) Hello World function\n",
        "void helloWorld()\n",
        "{\n",
        "    printf(\"Hello world!\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "// Device (GPU) Hello World kernel\n",
        "__global__ void helloWorldGPU()\n",
        "{\n",
        "    printf(\"Hello world from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    helloWorld();\n",
        "    helloWorldGPU<<<1,1>>>();\n",
        "    // Try commenting out this line\n",
        "    // Do you see GPU output? What does it mean?\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTI5mNCDWn_l"
      },
      "source": [
        "# 3. Vector Addition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9apFymzaDk4"
      },
      "source": [
        "## 3.1 Single Integer Addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkpxbCANV93p",
        "outputId": "6698e178-056d-4b12-f669-f772c1cc2823"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int a = 3, b = 2, c = 0;    // host copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;       // device copies of a, b, c\n",
        "    int size = sizeof(int);\n",
        "\n",
        "    //// Allocate memory to device\n",
        "    //// Allocate memory to d_a, d_b, and d_c using the following example\n",
        "    /* YOUR CODE HERE */\n",
        "    // cudaMalloc((void **)&d_a, size);\n",
        "\n",
        "\n",
        "    //// Copy inputs to device\n",
        "    //// Copy input to d_a, d_b using the following example\n",
        "    /* YOUR CODE HERE */\n",
        "    // cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    //// Launch kernel\n",
        "    add<<<1, 1>>>(d_a, d_b, d_c);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    //// What is the difference of this line compared to above cudaMemcpy?\n",
        "    /* YOUR CODE HERE */\n",
        "    // cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    //// print result, is result 5 instead of 0?\n",
        "    printf(\"%d\\n\", c);\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c with following example\n",
        "    /* YOUR CODE HERE */\n",
        "    // cudaFree(d_a);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBUJ9obZE0X"
      },
      "source": [
        "## 3.2 Vector Addition with Thread Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCShs6fHY9zm"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 16\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    //// We are using the same number of blocks as the array length\n",
        "    c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = sizeof(int) * N;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    int *b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    int *c = (int *)malloc(size);\n",
        "    memset(c, 0, size);\n",
        "\n",
        "    // device copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    //// Allocate memory to d_a, d_b, and d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Copy input to d_a, d_b\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Launch kernel\n",
        "    //// N is placed in left side of the brackets (blocks)\n",
        "    add<<<N, 1>>>(d_a, d_b, d_c);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// print result, is result correct?\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"i = %d, %d + %d = %d\\n\", i, a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Of course the same for host memory, too.\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_OkH0oiZF56"
      },
      "source": [
        "## 3.3 Vector Addition with Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqpNwNEwZJvx"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 16\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    //// We are using the same number of threads as the array length\n",
        "    c[threadIdx.x] = a[threadIdx.x] + b[threadIdx.x];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = sizeof(int) * N;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    int *b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    int *c = (int *)malloc(size);\n",
        "    memset(c, 0, size);\n",
        "\n",
        "    //// device copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    //// Allocate memory to d_a, d_b, and d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Copy input to d_a, d_b\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Launch kernel\n",
        "    //// N is placed in right side of the brackets (threads)\n",
        "    add<<<1, N>>>(d_a, d_b, d_c);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "\n",
        "    //// print result, is result correct?\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"i = %d, %d + %d = %d\\n\", i, a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Of course, we need to do the same for host memory, too.\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99Yti9NAZKJH"
      },
      "source": [
        "## 3.4 Vector Addition with Thread Blocks and Threads (Grids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6btiNdXeZXEL"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 32\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    // We now use both blockIdx and threadIdx!\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    c[idx] = a[idx] + b[idx];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = sizeof(int) * N;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    int *b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    int *c = (int *)malloc(size);\n",
        "    memset(c, 0, size);\n",
        "\n",
        "    // device copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    //// Allocate memory to d_a, d_b, and d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Copy input to d_a, d_b\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Launch kernel\n",
        "    int NUMBLOCKS = N / BLOCK_SIZE;\n",
        "    add<<<NUMBLOCKS, BLOCK_SIZE>>>(d_a, d_b, d_c);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// print result, is result correct?\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"i = %d, %d + %d = %d\\n\", i, a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "\n",
        "    //// Of course the same for host memory, too.\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuBDQ18oZYTD"
      },
      "source": [
        "## 3.5 Arbitrary Length Vector Addition\n",
        "\n",
        "We have been using array lengths divisible by `BLOCK_SIZE`. What can happen if we have lists of arbitrary length? \n",
        "\n",
        "How can we support lists of arbitrary length with fixed `BLOCK_SIZE`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myp02aZQWrqx"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// Arbitrary array length\n",
        "#define N 50\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Why length variable is added to the kernel now?\n",
        "__global__ void add(int *a, int *b, int *c, int len)\n",
        "{\n",
        "    // check the difference here\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < len)\n",
        "    {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = sizeof(int) * N;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    int *b = (int *)malloc(size);\n",
        "    random_ints(b, N);\n",
        "    int *c = (int *)malloc(size);\n",
        "    memset(c, 0, size);\n",
        "\n",
        "    // device copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    //// Allocate memory to d_a, d_b, and d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Copy input to d_b using the following example\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Launch kernel\n",
        "    //// what's the difference here?\n",
        "    int NUMBLOCKS = (N - 1) / BLOCK_SIZE + 1;\n",
        "    add<<<NUMBLOCKS, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// print result, is result correct?\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"i = %d, %d + %d = %d\\n\", i, a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "    //// Of course the same for host memory, too.\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3rMoWQvaYcW"
      },
      "source": [
        "## 3.6 Matrix Addition\n",
        "\n",
        "Use `dim3` structure to use (x, y, z) coordinates in thread blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cet7nlByayGy"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// 7 x 7 Matrix\n",
        "#define N_X 7\n",
        "#define N_Y 7\n",
        "\n",
        "// 4 x 4 blocksize\n",
        "#define BLOCK_SIZE_X 4\n",
        "#define BLOCK_SIZE_Y 4\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c, int len_x, int len_y)\n",
        "{\n",
        "    // Calculate yidx and xidx yourself. Use blockIdx, blockDim, and threadIdx\n",
        "    /* YOUR CODE HERE */\n",
        "    int yidx = ;\n",
        "    int xidx = ;\n",
        "\n",
        "    // What needs to be checked here?\n",
        "    if ()\n",
        "    {\n",
        "        // What is the index we should use here?\n",
        "        c[] = a[] + b[];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = sizeof(int) * N_X * N_Y;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N_X * N_Y);\n",
        "    int *b = (int *)malloc(size);\n",
        "    random_ints(b, N_X * N_Y);\n",
        "    int *c = (int *)malloc(size);\n",
        "    memset(c, 0, size);\n",
        "\n",
        "    // device copies of a, b, c\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    //// Allocate memory to d_a, d_b and d_c\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "\n",
        "    //// Copy input to d_a, d_b\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "\n",
        "    //// Launch kernel\n",
        "    //// what is the difference here? We use dim3 struct (x, y, z)\n",
        "    dim3 NUMBLOCKS = {(N_X - 1) / BLOCK_SIZE_X + 1, (N_Y - 1) / BLOCK_SIZE_Y + 1 ,1};\n",
        "    add<<<NUMBLOCKS, {BLOCK_SIZE_X, BLOCK_SIZE_Y, 1}>>>(d_a, d_b, d_c, N_X, N_Y);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //// Copy result from device (d_c) to host (c)\n",
        "    /* YOUR CODE HERE */\n",
        "\n",
        "\n",
        "\n",
        "    //// print result, is result correct?\n",
        "    for (int i = 0; i < N_Y; i++)\n",
        "    {\n",
        "        for (int j = 0; j < N_X; j++)\n",
        "        {\n",
        "            printf(\"i = %d, j = %d, %d + %d = %d\\n\", i, j, a[i*N_X + j], b[i*N_X + j], c[i*N_X + j]);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    //// Clean up memory for d_a, d_b, d_c\n",
        "\n",
        "\n",
        "    //// Of course the same for host memory, too.\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.7 Benchmark for 400M vector subtraction\n",
        "\n",
        "We subtract `a` from `a` for an easier validation of calculation, all elements in `c` must be 0 after calculation!\n",
        "\n",
        "Why GPU time takes longer than CPU computation meanwhile GPU computation itself takes way shorter than CPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "#define N 400000000     // 400M elements\n",
        "\n",
        "#define BLOCK_SIZE 1024\n",
        "\n",
        "void random_ints(int *a, int n)\n",
        "{\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        a[i] = rand() % 10;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sub(int *a, int *c, int len)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < len)\n",
        "    {\n",
        "        c[idx] = a[idx] - a[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "void sub_cpu(int *a, int *c, int len)\n",
        "{\n",
        "    for (int i = 0; i < len; i++)\n",
        "    {\n",
        "        c[i] = a[i] - a[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void gpu(int *a, int *c, int len)\n",
        "{\n",
        "    size_t size = sizeof(int) * N;\n",
        "    // device copies of a, c\n",
        "    int *d_a, *d_c;\n",
        "\n",
        "    // Allocate memory to device\n",
        "    // Allocate memory to d_b and d_c using the following example\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    //// Copy inputs to device\n",
        "    //// Copy input to d_b using the following example\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //// Launch kernel\n",
        "    //// what's the difference here?\n",
        "    int NUMBLOCKS = (N - 1) / BLOCK_SIZE + 1;\n",
        "\n",
        "    struct timeval gpustart, gpuend;\n",
        "    gettimeofday(&gpustart, NULL);\n",
        "    sub<<<NUMBLOCKS, BLOCK_SIZE>>>(d_a, d_c, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    gettimeofday(&gpuend, NULL);\n",
        "\n",
        "    double secs = (double)(gpuend.tv_usec - gpustart.tv_usec) / 1000000 + (double)(gpuend.tv_sec - gpustart.tv_sec);\n",
        "    printf(\"gpu computation time taken %f s\\n\", secs);\n",
        "\n",
        "    //// Copy result from device to host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    //// Clean up memory for d_a, d_c\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_c);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    size_t size = sizeof(int) * N;\n",
        "    int *a = (int *)malloc(size);\n",
        "    random_ints(a, N);\n",
        "    int *c = (int *)malloc(size);\n",
        "    random_ints(c, N);\n",
        "\n",
        "    // benchmark CPU (one thread)\n",
        "    struct timeval cpustart, cpuend;\n",
        "    gettimeofday(&cpustart, NULL);\n",
        "    sub_cpu(a, c, N);\n",
        "    gettimeofday(&cpuend, NULL);\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        assert(c[i] == 0);\n",
        "    }\n",
        "\n",
        "    double secs = (double)(cpuend.tv_usec - cpustart.tv_usec) / 1000000 + (double)(cpuend.tv_sec - cpustart.tv_sec);\n",
        "    printf(\"cpu computation time taken %f s\\n\", secs);\n",
        "\n",
        "    // reset c with random values\n",
        "    random_ints(c, N);\n",
        "\n",
        "    // benchmark GPU\n",
        "    struct timeval gpustart, gpuend;\n",
        "    gettimeofday(&gpustart, NULL);\n",
        "    gpu(a, c, N);\n",
        "    gettimeofday(&gpuend, NULL);\n",
        "\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        assert(c[i] == 0);\n",
        "    }\n",
        "\n",
        "    secs = (double)(gpuend.tv_usec - gpustart.tv_usec) / 1000000 + (double)(gpuend.tv_sec - gpustart.tv_sec);\n",
        "    printf(\"gpu time taken %f s\\n\", secs);\n",
        "\n",
        "    //// Memory cleanup!\n",
        "    free(a);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.8 Submit benchmarks of subtraction 50000 x 50000 array!\n",
        "\n",
        "Using above benchmark code, try to write your own 2D matrix subtraction kernel with benchmark results and send me a PR to this repo!\n",
        "\n",
        "You can write your own code in any way (do not need to be this notebook!) you would like, but it needs to be CPU vs GPU with different configurations of `BLOCK_SIZE`, array size, etc.\n",
        "\n",
        "The instructions are in `README.md` file!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvvUddDwZwaX"
      },
      "source": [
        "# 4. Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyvsz0cKbOwm"
      },
      "source": [
        "## Parallel Algorithm Example 1\n",
        "## 4.1 1D reduction (1D max, min, sum, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxSXRa8NbHLK"
      },
      "source": [
        "## 4.2 Resources:\n",
        "\n",
        "Books: Programming Massively Parallel Processors 4th Edition \n",
        "\n",
        "![PMPP](https://github.com/user-attachments/assets/01cf0739-d720-4ec4-9c83-412c7ac9d824)\n",
        "\n",
        "LLM Specific: [llm.c](https://github.com/karpathy/llm.c) by Andrej karpathy\n",
        "\n",
        "## 4.3 Answers:\n",
        "\n",
        "Notebook with answers with cuda code can be found in `answer` branch of the repository."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
